
**残差连接** —— 它是 Transformer 能够构建深度模型（如 GPT-3 的 96 层、LLaMA 2 的 70 层）的核心技术之一，解决了深度神经网络的梯度消失 / 爆炸问题，同时保留底层特征信息。

## 1. 原理

残差连接最早由 ResNet 论文提出，Transformer 直接沿用并适配其架构特点，核心逻辑是：让网络层学习 “残差”（输入与输出的差值），而非直接学习完整的映射关系。

### 1.1 数学定义

### 1.2 残差连接位置

Transformer 的每一个子层（自注意力层、前馈网络层）都包裹残差连接 + 归一化，有两种经典范式：

+ Post-Norm

+ Pre-Norm

## 2. 作用

### 2.1 解决深度模型的梯度消失/爆炸问题
