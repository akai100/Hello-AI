
**LangChain 的 Chat Model 是对「对话式大语言模型」的统一封装接口** —— 专门适配以「消息（Message）」为输入输出的 LLM（如 ChatGPT、Llama 3、文心一言等），
区别于传统的「文本输入→文本输出」的纯文本模型，是构建多轮对话、AI Agent 等交互类应用的核心组件。

## 1. 核心定位：对话式 LLM 的统一交互层

1. 与纯文本 Model 的核心区别

+ Chat Model

  输入形式：消息列表（Message）：包含角色（用户 / 助手 / 系统）+ 内容

  输出形式：单个 AIMessage（助手消息）

+ LLM（纯文本模型）

  输入形式：纯字符串文本

  输出形式：纯字符串文本

## 2. 核心概念

Chat Model 的输入不是纯文本，而是 BaseMessage 的子类列表，LangChain 定义了 4 种核心消息类型，覆盖所有对话场景：

+ SystemMessage

  角色：系统

  用途：设定助手的行为准则 / 背景信息

  示例：SystemMessage(content="你是一个专业的天气助手，回答简洁明了")

+ HumanMessage

  角色：用户

  用途：用户的提问 / 指令

  示例：HumanMessage(content="北京今天的天气怎么样？")

+ AIMessage

  角色：助手

  通途：模型的回复（多轮对话中作为历史）

  示例：AIMessage(content="北京今天晴，温度10-22℃")

+ FunctionMessage

  角色：工具

  用途：工具调用的返回结果（Agent 场景）

  示例：FunctionMessage(name="get_weather", content='{"city":"北京","temp":16}')

**2. 核心输出：AIMessage**

Chat Model 的输出是单个 AIMessage 对象，包含：

+ content：模型的文本回复（核心）；

+ additional_kwargs：额外信息（如工具调用指令、token 消耗、模型名称）；

+ response_metadata：响应元数据（如耗时、状态码）;


## 3. 使用方式

## 4. 高级特性

**1. 流式输出**

**2. 工具调用**

**3.批量调用**
