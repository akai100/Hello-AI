## DataCollator

DataCollator å†³å®šï¼š

**â€œDataset é‡Œä¸€æ¡ä¸€æ¡çš„æ•°æ®ï¼Œå¦‚ä½•æ‹¼æˆä¸€ä¸ª batchâ€**

## ä¸ºä»€ä¹ˆéœ€è¦ DataCollator

Dataset çš„å®é™…æƒ…å†µ

```
dataset[0] = {"input_ids": [101, 2054, 102]}
dataset[1] = {"input_ids": [101, 2023, 2003, 1037, 7099, 102]}
```

é•¿åº¦ä¸ä¸€æ ·ï¼Œä¸èƒ½ç›´æ¥å †æˆ tensor

### DataCollator èŒè´£

åœ¨ DataLoader å–åˆ°ä¸€æ‰¹æ ·æœ¬åï¼š

```
[List[Dict]]  â†’  Dict[str, Tensor]
```

å¹¶å®Œæˆï¼š

+ padding

+ å¯¹é½ labels

+ æ„é€  attention_mask

+ ä»»åŠ¡ç‰¹å®šå¤„ç†ï¼ˆMLM / seq2seq / CLMï¼‰


## æœ€å¸¸ç”¨çš„ DataCollator ç±»å‹

### DefaultDataCollatorï¼ˆæœ€ç®€å•ï¼‰

ç‰¹ç‚¹

+ ä¸åš padding

+ åªåš list â†’ tensor

+ è¦æ±‚ Dataset å·²ç» padding å¥½

+ âŒ ä¸æ¨èç”¨äºå¤§å¤šæ•° NLP ä»»åŠ¡

### DataCollatorWithPadding

+ åŠ¨æ€ paddingï¼ˆpad åˆ° batch æœ€å¤§é•¿åº¦ï¼‰

+ è‡ªåŠ¨ç”Ÿæˆ attention_mask

+ é€Ÿåº¦å¿«ã€çœæ˜¾å­˜

### DataCollatorForLanguageModelingï¼ˆMLM / CLMï¼‰

```python
from transformers import DataCollatorForLanguageModeling

collator = DataCollatorForLanguageModeling(
    tokenizer,
    mlm=True,
    mlm_probability=0.15
)
```

**é¢å¤–åŠŸèƒ½**

+ åŠ¨æ€ mask token

+ æ„é€  labels

+ é mask token çš„ label = -100

ğŸ‘‰ BERT é¢„è®­ç»ƒå¿…ç”¨
