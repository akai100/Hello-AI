🎯 本模块目标

你要做到：

**能解释 Scheduler 如何在吞吐、延迟、公平性之间做取舍**

## 1️⃣ Scheduler 到底在调什么？

很多人误以为 Scheduler 只是“排队”。

**实际上它在调三件事：**

1. 哪些请求进入下一步 decode

2. 谁先谁后（顺序）

3. 显存和 KV block 如何分配

📌 面试金句：

+ “Scheduler 决定了 GPU 在每一个 decode step 上为谁工作。”

## 2️⃣ 三个核心目标（必考）

**① 高吞吐（Throughput）**

+ 尽量让 batch 大

+ 尽量让 GPU 满载

**② 低延迟（Latency）**

+ 新请求尽快进入

+ 避免长请求拖死短请求

**③ 公平性（Fairness）**

+ 每个请求都能持续推进

+ 不饿死

**👉 三者天然冲突**

## 3️⃣ 最基础策略：FIFO（为什么不够？）

**FIFO 的问题**

+ 长请求在前：

  + 后面所有请求都慢

+ tail latency 爆炸

📌 面试官金句：

+ “FIFO 对异构请求非常不友好。”

## 4️⃣ Round-Robin（基本公平）

**思想**

+ 每个请求每 step 生成 1 token

+ 轮流来

**好处**

+ 不会饿死

+ 公平

**问题**

+ 没有优先级

+ 无法保证低延迟请求

## 5️⃣ 引入优先级（Priority Scheduling）

**常见优先级维度**

+ 新请求（降低 TTFT）

+ 短请求

+ 高 SLA 请求

📌 面试官金句：

+ “Scheduler 往往会优先保证 TTFT，而不是总生成时间。”

## 6️⃣ 抢占（Preemption）：系统级杀器

这是 3.2 的重点。

**什么是抢占？**

+ 暂停一个正在 decode 的请求

+ 释放其资源

+ 执行更高优先级请求

👉 类似 OS 的进程调度。

**vLLM 里的抢占方式（关键）**

**❌ 不直接抢 GPU**

太贵。

**✅ 抢 KV Cache**

+ 长请求 KV 被 swap out / 释放

+ 让位给新请求

📌 面试官金句：

+ “vLLM 的抢占本质是 KV Cache 的抢占。”

## 7️⃣ 抢占的 trade-off（必问）

**代价**

+ KV Cache 需要重新加载

+ 额外内存拷贝

+ latency 抖动

**为什么仍然值得？**

+ 防止长请求霸占系统

+ 保证 SLA

## 8️⃣ 一个「大厂级回答模板」

你可以这样回答 Scheduler 设计：

```
“vLLM 的 Scheduler 在 step 级别调度请求，
通过 Continuous Batching 保证 GPU 利用率。
在此基础上，引入公平和优先级策略，
例如优先调度新请求以降低 TTFT，
并在必要时通过抢占 KV Cache 的方式让高优先级请求先执行。
虽然抢占会带来一定的开销，但可以防止长请求占用系统资源，
在吞吐、延迟和公平性之间取得平衡。”
```

## 9️⃣ 本模块作业（系统设计级）

**作业（必做）**

**为什么 vLLM 的抢占选择抢 KV Cache，而不是直接抢 GPU？**

要求：

+ 必须提到：
  + GPU kernel 粒度
  + KV Cache 生命周期
  + 代价对比
