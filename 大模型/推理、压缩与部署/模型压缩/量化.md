
量化是降低大模型显存占用、提升推理/训练速度的核心技术。

## 核心原理

### 本质：用低精度替代高精度

大模型默认采用 32 位浮点数（FP32）存储参数，量化的核心是将高精度数据（FP32/FP16/BF16）转换为低精度数据（INT8/INT4/INT2），同时尽可能保留模型的精度。

**核心公式（以INT8 量化为例）**

$$x_{int8} = round(\frac{x_{fp32} - \text{min}}{scale}) + \text{zero\\_point}$$
