微调是在预训练模型的基础上进行的，两者共享完全相同的模型结构（如 Transformer Decoder）、**权重初始化（预训练权重）**、**优化器配置（如 AdamW）**、**训练循环（前向传播→反向传播→参数更新）**。

从工程角度看，微调的代码框架可以直接复用预训练的代码，仅需修改两个模块：

+ 数据处理模块

  修改输入格式，适配指令-响应对；

+ 损失计算模块

  添加 loss mask，仅计算响应部分的损失；

这也是工业界实现微调的核心工程原则：**最小化代码修改**，**最大化复用预训练框架**。


## 输入格式（instruction/response） - 数据层的约束

**1. 预训练的输入格式**

预训练的核心任务是语言建模，输入格式是**无结构的纯文本序列**。

工程实现上，输入就是一个连续的 token ID 序列，模型的目标是根据前面的 token 预测下一个 token（自回归语言建模）。

**2. 微调的输入格式**

微调的核心任务是**指令遵循（Instruction Following）**，输入格式是**结构化的指令 - 响应对（Instruction-Response Pair）**，工程上必须将其拼接为一个连续的 token 序列，并通过特殊分隔符区分指令和响应部分。

工业界最通用的微调输入格式：

```
<s> [INST] 请介绍一下大模型的微调 [/INST] 大模型的微调是在预训练模型的基础上，使用小批量的指令数据进行训练，以提升模型的指令遵循能力。 </s>
```

其中：

+ <s>：句子开始标记；

+ [INST] / [/INST]：指令的开始 / 结束标记；

+ 指令部分（Prompt）：请介绍一下大模型的微调；

+ 响应部分（Response）：大模型的微调是在预训练模型的基础上，使用小批量的指令数据进行训练，以提升模型的指令遵循能力。

+ </s>：句子结束标记。

**3. 工程实现的关键**

+ 数据预处理

  必须编写专门的函数，将原始的指令 - 响应对（如 JSON 格式）转换为上述结构化的 token 序列；

+ 特殊标记的处理

  若预训练时没有[INST]等特殊标记，需要在词表中追加特殊标记，并随机初始化其嵌入向量（这是微调中唯一需要新增的参数）；

+ 序列长度限制

  指令 + 响应的总长度不能超过模型的最大上下文长度（如 2048、4096），工程上需要做截断处理。

## loss mask（只算 response，不算 prompt）—— 损失计算层的约束

### 预训练的损失计算

预训练的损失是整个输入序列的自回归损失，即对每个 token都计算预测损失，然后取平均值。

### 微调的损失计算

微调的核心目标是**让模型根据指令生成正确的响应**，因此只有**响应部分（Response）的损失需要被计算，指令部分（Prompt）的损失必须被屏蔽。**

工程上的实现方法是**使用 loss mask：**

1. 构建一个与输入序列长度相同的mask 张量，其中：

+ 指令部分（Prompt）的 mask 值为-100（PyTorch 中CrossEntropyLoss会忽略标签为-100的损失）；

+ 响应部分（Response）的 mask 值为对应的目标 token ID；

2. 将 mask 张量作为labels传入模型，计算损失时，仅响应部分的损失会被计算。
