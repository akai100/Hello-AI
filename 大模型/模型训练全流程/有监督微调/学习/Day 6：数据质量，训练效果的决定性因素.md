## 🎯 今日能力目标

到今天结束，你需要掌握：

1. SFT（Supervised Fine-Tuning）数据集构建的原则和方法

2. 数据处理中的常见问题，特别是数据标注与清洗

3. 如何高效创建和利用指令数据

4. 如何在多任务训练中管理数据

## 1️⃣ SFT 数据集构建的原则和方法

SFT（Supervised Fine-Tuning） 是深度学习模型微调的常见方法，特别是在大模型上进行迁移学习时。SFT 的关键是选择和处理高质量的训练数据。

**SFT 数据集的构建：**

1. 任务驱动数据集：

+ 目标明确：根据具体的应用场景或任务（如问答、文本生成、分类任务等）设计数据集。

+ 质量至上：确保数据集中的标注准确无误，并符合模型预期的输入输出格式。

2. 高质量数据标注：

+ 使用专业的标注人员，确保数据集标注的准确性。

+ 数据集中的类别标签和数据质量必须一致，避免错误标注影响模型的学习。

3. 数据多样性：

+ 确保数据集涵盖了任务中可能遇到的各种场景，以提升模型的泛化能力。

包+ 含各种语言风格、不同话题、不同情境的数据，避免模型对某些场景的偏见。

4. 平衡数据：

+ 如果数据集中某些类别的数据远少于其他类别（数据不平衡），考虑使用过采样或欠采样技术，或在训练时使用类别加权损失函数。

## 2️⃣ 数据清洗与标注的常见问题

**数据标注错误：**

+ 标签错误：标注不一致或错误，导致模型学习到错误的关联，影响最终的性能。

+ 不一致性：不同的数据标注人员可能会有不同的理解和标注方式，造成数据不一致。

**数据缺失：**

+ 缺失值问题：数据集中存在缺失的标签或输入特征，训练模型时可能会遇到困难。

+ 解决方法：通过插值法、数据增强或直接丢弃缺失的样本来解决。

**数据去重：**

+ 重复数据：训练数据中的重复样本会导致模型过拟合，降低模型的泛化能力。

+ 解决方法：进行数据去重，去除重复样本，避免数据冗余。

**噪声数据：**

+ 噪声数据：无关、错误或者不准确的数据会影响模型学习，使其产生偏差。

+ 解决方法：可以通过数据清洗和异常值检测等方法去除噪声数据。

## 3️⃣ 高效利用指令数据

指令数据是近年来在大模型训练中应用广泛的技术，尤其是在训练能够处理复杂对话和任务的模型（如 ChatGPT、BERT 等）时，指令数据能够帮助模型更好地理解任务目标。

**指令数据的重要性：**

+ 任务明确：模型通过明确的指令（例如“翻译以下文本”）来理解任务目标，能够提升处理各种任务的能力。

+ 提高适应性：通过指令数据，模型可以处理更多种类的输入，扩展到不同的应用场景（如问答、摘要生成、翻译等）。

**指令数据集构建：**

1. 生成指令-响应对：

+ 每个指令（例如“将以下英文翻译为中文”）与其对应的正确响应（翻译结果）构成一个训练样本。

2. 数据多样性：

+ 创建多种类型的指令，覆盖不同的任务，增强模型对不同任务的适应能力。

3. 高质量的人工标注：

+ 确保指令数据中每个响应都是准确的，并且符合任务要求。

## 4️⃣ 多任务训练中的数据管理

在进行多任务训练时，数据的管理显得尤为重要，特别是在大规模模型训练中，如何有效组织和利用不同任务的数据集，保证训练过程的高效性和模型的准确性，是关键。

**多任务训练数据管理：**

1. 数据集划分：

+ 对于每个任务，单独划分训练集、验证集和测试集。保证每个任务的数据都能够独立地进行评估和调优。

2. 任务加权：

+ 对于不同任务的重要性，可以通过加权的方法在训练过程中赋予不同的任务不同的权重。

3. 数据流的协调：

+ 确保多个任务的数据流不会相互干扰。例如，利用数据加载器对不同任务的数据进行分批处理，避免任务间的“数据污染”。

## 🧪 Day 6 实战任务

### ✅ 任务 1：构建 SFT 数据集

你正在进行一个分类任务，需要为一个新的领域构建 SFT 数据集。请列出你会遵循的 4 个关键步骤，确保数据集的质量。

**步骤：**

1. 确定任务目标和数据来源：

+ 首先要明确任务目标，例如分类任务、回归任务、问答任务等。

+ 数据来源可以是公开数据集、人工标注的数据集，或者使用爬虫等方式收集数据。必须确保数据的来源可靠且相关。

2. 数据标注和清洗：

+ 确保数据集中的标签是准确的。对于分类任务，要确保每个样本的标签清晰无误。

+ 清洗数据，去除无关样本、异常值和重复数据。确保数据中没有噪声，以免影响模型学习。

3. 数据划分和采样：

+ 将数据集划分为训练集、验证集和测试集，确保各个数据集的分布一致性。

+ 如果任务中某些类别的样本较少，可以考虑进行过采样或欠采样，以确保数据的平衡。

4. 生成多样化的训练样本：

+ 确保数据集中的样本具有多样性，涵盖各种场景和变体，以提高模型的泛化能力。

+ 特别是在SFT任务中，样本的多样性对于训练高质量的模型至关重要。

### ✅ 任务 2：数据清洗问题排查

你正在训练一个模型，发现在训练过程中，模型的性能一直没有提升，甚至出现了过拟合。你怀疑是数据问题，请列举 3 种可能导致数据问题的情况，并给出解决方法。

```
1. 标签错误：

问题：数据集中存在标签错误，模型可能学习到错误的关联。

解决方法：人工检查标签的准确性，并使用数据验证工具，如交叉验证，来确保标签的正确性。如果有大量标签错误，可以考虑通过半监督学习方法修正标签。

2. 数据缺失：

问题：数据中存在缺失值，导致模型无法正常训练。

解决方法：填补缺失值（例如，使用均值、众数、插值等方法），或者直接去除含有缺失值的样本（如果缺失较少）。对于时间序列数据，插值可能是更好的选择。

3. 数据噪声：

问题：数据集中存在噪声样本，可能是无关或错误的数据，影响模型的性能。

解决方法：通过数据清洗技术去除异常值，或者使用鲁棒算法（例如鲁棒回归）减少噪声的影响。也可以利用数据集的规则（如样本值范围、统计分布）来检测和去除异常数据。
```

### ✅ 任务 3：指令数据集构建

假设你要构建一个指令数据集，用于训练一个能够理解并执行自然语言指令的模型。请列出 3 个你会加入的典型指令-响应对，并解释为什么选择这些任务。

```
1. 指令-响应对 1：

指令：“将以下英文翻译为中文”

响应：“Hello, how are you?” → “你好，你怎么样？”

原因：翻译任务是指令数据集中常见的任务，能够帮助模型学习多语言转换。

2. 指令-响应对 2：

指令：“请总结下面的文章要点”

响应：“本文讨论了人工智能在医疗领域的应用，包括诊断、治疗和患者管理等方面的最新进展。”

原因：摘要生成是文本处理的常见任务，有助于模型理解内容并提取关键信息。

3. 指令-响应对 3：

指令：“从以下文本中提取出所有的公司名”

响应：“Google, Microsoft, Tesla”

原因：命名实体识别（NER）是文本处理中的基础任务，能够帮助模型学会从文本中识别关键信息，如公司名、地名、人物等。
```


## 🎯 今日验收标准

你能详细解释如何在大规模训练中 确保数据质量，并且能够构建 高质量的 SFT 数据集。

你能够快速识别 数据问题（如标签错误、数据缺失）并提供有效的解决方案。

你能设计合理的 指令数据集，并清晰理解 多任务训练中的数据管理。
