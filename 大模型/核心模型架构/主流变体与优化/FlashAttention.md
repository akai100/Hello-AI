
FlashAttention 是由斯坦福大学提出的**高效注意力计算算法**，核心解决传统多头注意力中“高显存占用、低访存效率”的问。

**1. 传统注意力的显存/效率问题**

+ 关键问题1

  $QK^T$ 会生成形状为 $(N, N)$ 的注意力分数矩阵，当 $N = 1024$ 时的矩阵大小为 $1024 \mult 2024 = 1M$

+ 关键问题 2

  传统计算需多次读写显存（Q/K/V→分数矩阵→Softmax→加权 V），访存开销远大于计算开销，GPU 算力利用率低;

**2. 核心原理：分块 + 重排 + 融合**

FlashAttention 通过**分块（Blocking）** 、**显存层级重排** 和 **计算 - 访存融合** 三大核心优化，将注意力计算的显存复杂度从 $O(N^2)$ 降至 $O(N)$ ，同时提升 GPU 访存效率：
