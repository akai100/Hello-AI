
卷积网络，也叫做卷积神经网络（convolutional neural network, CNN），是一种专门用来处理具有类似网格结构的数据的神经网络。

# 1. 卷积运算

$(f * g)[n] = \sum_{k=-\infty}^{\infty}{f[k]} \dot g[n-k]\\ $

+ $f$ : 输入信号

+ $g$ ：卷积核（如低通滤波，用于平滑噪声）

+ $*$ ：卷积运算符

+ $g[n-k]$：卷积核的翻转(先沿时间轴翻转，再平移)

# 2. CNN 中的卷积

在 CNN 中，我们不做卷积核翻转，而是直接计算滑动窗口的加权和，这种操作称为互相关。

$(f *g )[n]=\sum_{k}^{}{f[k] \dot g[k]}$

## 2.1 参数

+ 卷积核大小

  核越大，感受野越大（覆盖输入的区域越广），但参数越多、计算量越大；

+ 步长

  卷积核每次滑动的像素数，步长越大，输出特征图尺寸越小，计算量越低；

+ 填充

  边缘填充 0 的层数，保持输出尺寸与输入一致（Same Padding），避免边缘特征丢失；

+ 输出通道数

  卷积核的数量，通道数越多，提取的特征越丰富，但参数和计算量也越大


# 3. 卷积的本质

卷积能成为 CNN 的核心，是因为它完美契合了图像数据的两大特性：

+ 局部相关性

  图像的特征具有局部相关性：一个像素的含义往往由其周围像素决定（如边缘由相邻像素的灰度差构成）；

  + 卷积通过局部连接（只关注输入的局部区域），高效提取局部特征；
 
  + 相比全连接层（每个神经元连接所有输入像素），卷积层的参数数量大幅减少；
 
+ 平移不变形

   图像的特征具有平移不变性；

  + 卷积通过参数共享（同一个卷积核在整个输入上滑动），确保模型能识别不同位置的相同特征；

 # 2. 池化层

 池化层是卷积神经网络（CNN）中降采样的核心组件，作用是减小特征图尺寸、降低计算复杂度、增强特征的平移不变性，同时保留关键特征信息。

 ## 2.1 核心作用

 + 降维

   减小特征图的高度和宽度，减少后续层的参数量和计算量，避免过拟合；

+ 增强平移不变性

  即使输入特征有轻微平移，池化后的输出也基本保持一致，提升模型的泛化能力；

+ 保留关键特征

  聚焦于局部区域的显著特征（如最大值、平均值），过滤冗余信息；

+ 扩大感受野

  在不增加参数的前提下，让后续卷积层能捕捉更大范围的输入信息；

## 2.2 常见池化类型

### 2.2.1 最大池化

  这是最常用的池化方式，取局部窗口内的最大值作为输出；

+ 计算过程


+ 特点

  突出局部区域的最强特征（如边缘、纹理），对噪声有一定鲁棒性；

### 2.2.2 平均池化

取局部窗口内的平均值作为输出，分为普通平均池化和全局平均池化（GAP）。

1. 普通平均池化

   + 计算过程：与最大池化类似，但取窗口内所有像素的平均值
  
   + 特点：平滑特征，保留局部区域的整体信息，不过容易弱化强特征

2. 全局平均池化

   + 特殊点：池化窗口尺寸等于输入特征图的尺寸，对整个特征图取平均，输出为 1×1 的特征图；
  
   + 应用：常用于 CNN 的分类头，替代全连接层，减少参数量，提升模型泛化能力；

### 2.2.3 其他池化类型

+ 求和池化

  取窗口内像素值的总和，较少单独使用；

+ 自适应池化

  无需指定窗口和步长，直接指定输出尺寸，自动计算池化窗口大小；



### 2.3 关键参数

池化层的参数与卷积层类似，但没有可学习的权重，属于固定规则的操作。

1. 窗口尺寸

   池化窗口的大小，常用 2×2 或 3×3，2×2 是最经典的选择（可将特征图尺寸减半）

2. 步长

   窗口每次滑动的像素数，通常设置为与窗口尺寸相同（如K=2,S=2），避免窗口重叠，最大化降维效果；

3. 填充

   通常设为 0（Valid 模式），因为池化的目的是降维，填充会削弱降维效果；仅在需要保持特定尺寸时使用；


  
  

  

