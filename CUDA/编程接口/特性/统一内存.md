
统一内存编程有四种范式：

+ 完全支持显式托管内存分配;

+ 全面支持所有具有软件一致性的分配

+ 完全支持所有具有硬件一致性的分配

+ 有限的统一内存支持

## 1. 具有完整CUDA统一内存支持的设备上的统一内存


### 1.1 统一内存：深入示例

具有完整CUDA统一内存支持的系统（参见表统一内存范式概述）允许设备访问与该设备交互的主机进程所拥有的任何内存。

```c++
__global__ void kernel(const char* type, const char* data) {
    static const int n_char = 8;
    printf("%s - first %d characters: '", type, n_char);
    for (int i = 0; i < n_char; ++i) printf("%c", data[i]);
    printf("\n");
}
```

**1. Malloc**

```c++
void test_malloc()
{
    const char test_string[] = "Hello World";
    char* heap_data = (char *)malloc(sizeof(test_string));
    strncpy(heap_data, test_string, sizeof(test_string));
    kernel<<<1, 1>>>("malloc", head_data);
    free(heap_data);
}
```

**2. Managed**

```c++
void test_managed()
{
    const char test_string[] = "Hello World";
    char* data;
    cudaMallocManaged(&data, sizeof(test_string));
    strncpy(data, test_string, sizeof(test_string));
    kernel<<<1, 1>>>("managed", data);
    cudaFree(data);
}
```

**3. 栈变量**

```c++
void test_stack() {
  const char test_string[] = "Hello World";
  kernel<<<1, 1>>>("stack", test_string);
  ASSERT(cudaDeviceSynchronize() == cudaSuccess,
    "CUDA failed with '%s'", cudaGetErrorString(cudaGetLastError()));
}
```

请注意，对于外部变量，它可能由第三方库声明、拥有并管理其内存，而该第三方库完全不与CUDA交互。

还要注意，**栈变量**以及**文件作用域**和**全局作用域变量****只能由GPU通过指针访问**。在这个特定示例中，这很方便，因为字符数组已经被声明为指针：```const char*```。不过，请考虑以下具有全局作用域整数的示例：

#### 1.1.1 文件支持的统一内存

由于完全支持CUDA统一内存的系统允许设备访问主机进程拥有的任何内存，因此它们可以直接访问文件支持的内存。

#### 1.1.2 使用统一内存的进程间通信（IPC）

许多应用程序倾向于为每个进程管理一个GPU，但仍需要使用统一内存，例如用于超额订阅，并从多个GPU访问它。


CUDA IPC（参见进程间通信）不支持托管内存：此类内存的句柄不得通过本节讨论的任何机制共享。

在具有完整CUDA统一内存支持的系统上，系统分配的内存支持IPC。

一旦系统分配的内存的访问权限已与其他进程共享，就会应用相同的编程模型，类似于文件支持的统一内存。

## 2. 性能调优

为了使统一内存达到良好性能，重要的是：

+ 了解系统上的分页工作原理，以及如何避免不必要的页面错误;

+ 了解使数据能够保留在访问处理器本地的各种机制

+ 考虑针对系统内存传输的粒度来优化您的应用程序

作为一般性建议，性能提示（参见性能提示）可能会提升性能，但如果使用不当，与默认行为相比，性能可能会下降。另请注意，任何提示在主机上都有相关的性能成本，因此有用的提示至少必须能足够提升性能，以抵消这一成本。

### 2.1 内存分页和页面大小

为了更好地理解统一内存对性能的影响，了解**虚拟寻址**、**内存页**和**页大小**至关重要。

目前所有支持统一内存的系统都使用**虚拟地址空间**：这意味着应用程序使用的内存地址代表一个虚拟位置，该位置可能被映射到内存实际所在的物理位置。

所有当前受支持的处理器（包括CPU和GPU）都额外使用**内存分页**。由于所有系统都使用虚拟地址空间，因此存在**两种类型的内存页**：

+ 虚拟页面

  这表示操作系统跟踪的每个进程的固定大小连续虚拟内存块，可被映射到物理内存中。

  请注意，虚拟页面与映射相关联：例如，单个虚拟地址可能会使用不同的页面大小映射到物理内存中。

+ 物理页

  这指的是处理器的主内存管理单元（MMU）所支持的固定大小的连续内存块，虚拟页可映射到其中。


目前，所有x86_64 CPU都使用4KiB的默认物理页大小。

Arm CPU支持多种物理页大小——4KiB、16KiB、32KiB和64KiB，具体取决于确切的CPU型号。

最后，NVIDIA GPU支持多种物理页大小，但更倾向于2MiB或更大的物理页。请注意，这些大小在未来的硬件中可能会发生变化。



虚拟页的默认页大小通常与物理页大小相对应，但只要操作系统和硬件支持，应用程序可以使用不同的页大小。

通常，受支持的虚拟页大小必须是2的幂，并且是物理页大小的倍数。


跟踪虚拟页到物理页映射的逻辑实体被称为**页表**，而给定虚拟页（具有给定虚拟大小）到物理页的每个映射被称为**页表项（PTE）**。

所有受支持的处理器都为页表提供特定的缓存，以加快虚拟地址到物理地址的转换。这些缓存被称为**转换后备缓冲区（TLB）**。


应用程序性能调优有两个重要方面：

+ 虚拟页大小的选择；

+ 系统提供的是CPU和GPU共用的联合页表，还是CPU和GPU各自单独的页表；

#### 2.1.1 选择合适的页面大小

一般来说，较小的页面大小会减少（虚拟）内存碎片，但会增加TLB未命中；而较大的页面大小会增加内存碎片，但会减少TLB未命中。

此外，与较小的页面大小相比，较大页面大小的内存迁移通常成本更高，因为我们通常迁移完整的内存页面。

这可能会导致使用大页面大小的应用程序出现更大的延迟峰值。



性能调优的一个重要方面是，GPU 上的 TLB 缺失通常比 CPU 上昂贵得多。

这意味着，如果 GPU 线程频繁访问使用足够小的页面大小映射的统一内存的随机位置，与访问使用足够大的页面大小映射的统一内存的相同位置相比，其速度可能会明显变慢。

虽然 CPU 线程随机访问使用小页面大小映射的大面积内存时可能会出现类似的效果，但速度下降不太明显，这意味着应用程序可能希望在这种速度下降与减少内存碎片之间进行权衡。


#### 2.1.2 CPU和GPU页表：硬件一致性与软件一致性

像NVIDIA Grace Hopper这类硬件一致性系统，为CPU和GPU提供了一个逻辑上合并的页表。

这一点至关重要，因为当GPU要访问系统分配的内存时，会使用CPU为请求的内存创建的任何页表项。

如果该页表项使用4KiB或64KiB的默认CPU页大小，那么对大型虚拟内存区域的访问将导致大量的TLB缺失，进而造成显著的性能下降。



另一方面，在CPU和GPU各自拥有独立逻辑页表的软件一致性系统中，应考虑不同的性能调优方面：为了保证一致性，当一个处理器访问映射到另一个处理器物理内存中的内存地址时，这些系统通常会使用页面错误。这种页面错误意味着：

+ 需要确保当前拥有该物理页的处理器（即该物理页当前所在的处理器）无法再访问此页，这可以通过删除页表项或更新页表项来实现。

+ 支持这个虚拟页面的物理页面必须被移动/迁移到请求访问的处理器：这可能是一项代价高昂的操作，其工作量与页面大小成正比。



总体而言，在CPU和GPU线程都频繁并发访问同一内存页的情况下，硬件一致性系统比软件一致性系统具有显著的性能优势：

+ 更少的页面错误：这些系统不需要使用页面错误来模拟一致性或迁移内存。

+ 更少的冲突：这些系统在缓存行粒度上保持一致性，而非页面大小粒度。也就是说，当多个处理器在一个缓存行内产生冲突时，只需交换该缓存行，其大小远小于最小的页面大小；而当不同处理器访问一个页面内的不同缓存行时，则不会产生冲突。

这会影响以下场景的性能：

+ 从CPU线程向GPU线程发送信号，反之亦然。


#### 2.1.3 主机原生原子操作
  
包括硬件一致性系统中通过NVLink连接的设备在内的一些设备，支持对CPU驻留内存进行硬件加速的原子访问。

这意味着对主机内存的原子访问不必通过页面错误来模拟。

对于这些设备，属性```cudaDevAttrHostNativeAtomicSupported```被设置为1。

#### 2.1.4 原子访问和同步原语

CUDA统一内存支持主机线程和设备线程可用的所有原子操作，使所有线程能够通过并发访问相同的共享内存位置进行协作。

libcu++库提供了许多异构同步原语，这些原语针对主机线程和设备线程之间的并发使用进行了优化，包括cuda::atomic、cuda::atomic_ref、cuda::barrier、cuda::semaphore等。



在软件一致性系统上，设备对文件支持的主机内存的原子访问不受支持。以下示例代码在硬件一致性系统上有效，但在其他系统上会表现出未定义行为：




在硬件一致性系统上，主机和设备之间的原子操作不需要页面错误，但仍可能因其他可能导致任何内存访问出错的原因而产生错误。


#### 2.5 统一内存的 memcpy() /Memset()行为

```cudaMemcpy*()``` 和 ```cudaMemset*()``` 接受任何统一内存指针作为参数。

对于```cudaMemcpy*()```，以```cudaMemcpyKind```指定的方向是一种性能提示，如果任何参数是统一内存指针，这可能会对性能产生更大的影响。

因此，建议遵循以下性能方面的建议：

+ 当统一内存的物理位置已知时，请使用准确的cudaMemcpyKind提示;

+ 优先使用cudaMemcpyDefault，而非不准确的cudaMemcpyKind提示；

+ 始终使用已分配（已初始化）的缓冲区：避免使用这些API来初始化内存；

+ 如果两个指针都指向系统分配的内存，请避免使用```cudaMemcpy*()```：而是启动内核或使用CPU内存复制算法，例如```std::memcpy```。


#### 2.6 统一内存的内存分配器概述

+ ```malloc```, ```new```, ```mmap```, ```malloc```、```new```、mmap

  + First touch/hint [1] 首次触碰/提示 [1]
 
  + CPU, GPU 中央处理器、图形处理器
 

#### 2.7 访问计数器迁移

在硬件一致性系统上，访问计数器功能会跟踪GPU对位于其他处理器上的内存的访问频率。

这是确保内存页被移至最频繁访问这些页面的处理器的物理内存所必需的。它可以指导CPU与GPU之间以及对等GPU之间的迁移，这一过程称为访问计数器迁移。

#### 2.8  避免从CPU频繁写入GPU驻留内存

如果主机访问统一内存，缓存未命中可能会在主机和设备之间引入比预期更多的流量。

许多CPU架构要求所有内存操作都通过缓存层次结构进行，包括写入操作。

如果系统内存驻留在GPU上，这意味着CPU对该内存的频繁写入可能会导致缓存未命中，从而在将实际值写入请求的内存范围之前，先将数据从GPU传输到CPU。

在软件一致性系统上，这可能会引入额外的页面错误；而在硬件一致性系统上，这


#### 2.9 利用对系统内存的异步访问

如果应用程序需要将设备上的工作结果与主机共享，有几种可能的选择：

1. 该设备将其结果写入GPU驻留内存，结果通过cudaMemcpy*传输，然后主机读取传输的数据。

2. 设备将结果直接写入CPU驻留内存，主机读取该数据。

3. 设备写入驻留于GPU的内存，而主机直接访问该数据。

### 333333333333333333333333
