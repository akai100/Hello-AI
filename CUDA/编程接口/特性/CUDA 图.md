
CUDA图为CUDA中的工作提交提供了另一种模型。

图是由依赖项连接的一系列操作，如内核启动、数据移动等，这些操作与其执行分开定义。这允许定义一次图，然后重复启动。

将图的定义与其执行分开可以实现许多优化：首先，与流相比，CPU启动成本降低了，因为大部分设置是提前完成的；

其次，将整个工作流呈现给CUDA可以实现优化，而这在流的分段工作提交机制中可能是不可能的。



要了解图形所能实现的优化，不妨想想流处理中的情况：当你将一个内核放入流中时，主机驱动程序会执行一系列操作，为内核在GPU上的执行做准备。

这些用于设置和启动内核的操作是一种开销成本，每个被调用的内核都必须支付这种成本。

对于执行时间较短的GPU内核而言，这种开销成本可能在整个端到端执行时间中占很大一部分。

通过创建一个包含将被多次启动的工作流的CUDA图形，这些开销成本可以在实例化期间为整个图形支付一次，之后图形本身就可以以极低的开销重复启动。

## 1 图结构

一个操作在图中形成一个节点。操作之间的依赖关系构成边。这些依赖关系会限制操作的执行顺序。

一旦操作所依赖的节点完成，该操作可在任何时间被调度。调度由CUDA系统负责。

## 1.1 节点类型

图节点可以是以下之一：

+ 内核

+ CPU函数调用

+ 内存复制

+ 集

+ 空节点

+ 等待一个CUDA事件

+ 记录一个CUDA事件

+ 发出外部信号量

+ 等待外部信号量

+ 条件节点

+ 内存节点

+ 子图：执行一个单独的嵌套图

## 1.2 边缘数据

CUDA 12.3在CUDA图中引入了边数据。目前，非默认边数据的唯一用途是启用**编程式依赖启动**。

一般来说，边缘数据会修改由边缘指定的依赖关系，它由三部分组成：输出端口、输入端口和类型。

输出端口指定相关边缘何时被触发。

输入端口指定节点的哪一部分依赖于相关边缘。类型则修改端点之间的关系。


端口值特定于节点类型和方向，边缘类型可能仅限于特定的节点类型。

在所有情况下，零初始化的边缘数据代表默认行为。

输出端口0等待整个任务，输入端口0阻塞整个任务，边缘类型0与具有内存同步行为的完全依赖相关联。



在各种图形API中，边数据可以通过与关联节点并行的数组来选择性地指定。

如果作为输入参数省略，将使用零初始化数据。

如果作为输出（查询）参数省略，若被忽略的边数据均为零初始化，API会接受这种情况；若调用会丢弃信息，则返回 **cudaErrorLossyQuery**。



边缘数据在某些流捕获API中也可用：```cudaStreamBeginCaptureToGraph()```、```cudaStreamGetCaptureInfo()```和```cudaStreamUpdateCaptureDependencies()```。

在这些情况下，尚未存在下游节点。这些数据与悬垂边缘（半边缘）相关联，该边缘要么会连接到未来捕获的节点，要么会在流捕获终止时被丢弃。

请注意，某些边缘类型不会等待上游节点完全完成。

在判断流捕获是否已完全重新加入原始流时，这些边缘会被忽略，并且在捕获结束时不能被丢弃。



没有节点类型定义额外的传入端口，只有内核节点定义额外的传出端口。

有一种非默认的依赖类型，即```cudaGraphDependencyTypeProgrammatic```，它用于在两个内核节点之间启用可编程依赖启动。


## 2. 构建和运行图

使用图表提交工作分为三个不同的阶段：定义、实例化和执行。

+ 在定义或创建阶段，程序会创建图中操作的描述以及这些操作之间的依赖关系。

+ 实例化会对图模板进行快照、验证，并执行大量设置和初始化工作，目的是尽量减少启动时需要完成的操作。生成的实例被称为可执行图。

+ 一个可执行图可以被启动到流中，类似于任何其他CUDA工作。它可以被启动任意多次，而无需重复实例化。

### 2.1 图的创建

图形可以通过两种机制创建：使用显式图形API和通过流捕获。



#### 2.1.1 图 API

以下是创建下图的示例（省略了声明和其他样板代码）。


注意使用```cudaGraphCreate()```来创建图，以及使用```cudaGraphAddNode()```来添加内核节点及其依赖项。

CUDA运行时API文档列出了所有可用于添加节点和依赖项的函数。



上面的示例展示了四个内核节点及其之间的依赖关系，以说明一个非常简单的图的创建。

在典型的用户应用程序中，还需要添加用于内存操作的节点，例如```cudaGraphAddMemcpyNode()```等。

#### 2.1.2 流捕获

流捕获提供了一种从现有**基于流的API创建图形**的机制。

一段将工作加载到流中的代码（包括现有代码）可以用```cudaStreamBeginCapture()```和```cudaStreamEndCapture()```的调用括起来。如下所示



调用```cudaStreamBeginCapture()```会将流置于捕获模式。

当流处于捕获状态时，启动到该流中的工作不会被排入执行队列，而是会附加到一个正在逐步构建的内部图中。

然后，通过调用```cudaStreamEndCapture()```可以返回该图，同时结束流的捕获模式。由流捕获主动构建的图被称为捕获图。



流捕获可用于任何CUDA流，但```cudaStreamLegacy```（即“NULL流”）除外。请注意，它可以用于```cudaStreamPerThread```。



可以使用```cudaStreamIsCapturing()```查询流是否正在被捕获。



可以使用```cudaStreamBeginCaptureToGraph()```将工作捕获到现有图中。与捕获到内部图不同，工作会被捕获到用户提供的图中。

##### 2.1.2.1 跨流依赖关系和事件

流捕获可以处理通过```cudaEventRecord()```和```cudaStreamWaitEvent()```表达的跨流依赖关系，前提是所等待的事件已记录到同一个捕获图中。

```
CUDA 中跨留的执行依赖，是通过两个 API 配合的实现：

cudaEventRecord(): 将一个 cudaEvent_t 记录到某个流中，代表该流执行到这一位置时事件触发；

cudaStreamWaitEven(): 让目标流等待某个事件，只有事件触发后，该流后续的操作才会执行，

2. 流捕获的处理能力

流捕获的核心是把多个流的操作“录制”成一个 CUDA 图，录制过程中会自动解析并保留跨流依赖 —— 前提是是依赖的“事件”满足归属要求。

3. 关键前提：事件需记录到同一捕获图

(1) 若 cudaStreamWaitEvent() 等待的事件，是通过 cudaEventRecord() 记录到当前正在捕获的同一个图内的某个流中：流捕获会识别

到这个依赖关系，并将其固化到生成的CUDA 图里，后续执行图时，跨流依赖会被正确执行；

(2) 若事件是在捕获图之外记录的（比如捕获开始前、或另一个捕获图中）：流捕获无法识别该依赖，可能导致依赖失效（比如等待的事件

永远不触发，或执行顺序错乱），
```

当事件被记录在处于捕获模式中的流中时，会产生一个捕获的事件。捕获的事件表示捕获图中的一组节点。

当一个被捕获的事件被流等待时，如果该流尚未处于捕获模式，它会将流置于捕获模式，并且流中的下一个项目将对被捕获事件中的节点具有额外的依赖
关系。这两个流随后被捕获到同一个捕获图中。


当流捕获中存在跨流依赖时，仍必须在调用 ```cudaStreamBeginCapture()``` 的同一流（即源流）中调用 ```cudaStreamEndCapture()```。
由于基于事件的依赖关系，任何其他被捕获到同一捕获图的流也必须重新关联到源流。如下所示。在调用```cudaStreamEndCapture()```后，所有
被捕获到同一捕获图的流到将退出捕获莫斯。如果未能重新关联到源流，整个捕获操作将会失败。

```c++
cudaStreamBeginCapture(stream1);

kernel_A<<<...., stream1>>>(...);

// Fork into stream2
cudaEventRecored(event1, stream1);
cudaStreamWaitEvent(stream2, event1);

kernel_B<<< ..., stream1 >>>(...);
kernel_C<<< ..., stream2 >>>(...);
```

##### 2.1.2.2 禁止和未处理的操作

##### 2.1.2.3 失效

##### 2.1.2.4 捕获内省

#### 2.1.3 整合所有内容

### 2.2 图实例化

### 2.3 图执行

## 3. 更新实例化图

### 3.1 整个图更新

### 3.2 单个节点更新

### 3.3 单个节点启用

### 3.4 图更新限制

## 4. 条件图节点

### 4.1 条件句柄

### 4.2 条件节点主体图要求

### 4.3 条件 IF 节点

### 4.4 条件 WHILE 节点

### 4.5 条件 SWITCH 节点

## 5. 图内存节点

### 5.1 简介

### 5.2 API 基础

#### 5.2.1 图节点 API

#### 5.2.2 流捕获

#### 5.2.3 在分配图外部访问和释放图内存

#### 5.2.4 cudaGraphInstantiateFlagAutoFreeOnLaunch

#### 5.2.5 子图中的内存节点

### 5.3 优化的内存重用

#### 5.3.1 图内地址重用

#### 5.3.2 物理内存管理与共享

### 5.4 性能考量




                                                                                                         


