## 1. 简介

图内存节点允许图创建并拥有内存分配。图内存节点具有GPU有序的生命周期语义，这规定了内存何时可以在设备上被访问。这些GPU有序的生命周期语义支持驱动程序管理的内存重用，
并与流有序分配API ```cudaMallocAsync```和```cudaFreeAsync```的语义相匹配，在创建图时可能会捕获这些API。

图分配在图的整个生命周期（包括重复实例化和启动）中具有固定地址。这使得图中的其他操作可以直接引用该内存，无需更新图，即使CUDA更改了支持的物理内存也是如此。
在一个图中，图顺序生命周期不重叠的分配可以使用相同的底层物理内存。

```
1. 核心特性：图分配的 “地址固定性”

“图分配”（可理解为计算图中为数据 / 张量预留的内存空间）在整个图生命周期（包括图被多次创建实例、启动执行的全过程）中，
其 “逻辑地址” 是固定的。

（1）这里的 “固定” 不是指物理内存地址不变，而是图内部的 “引用标识” 不变 —— 图中其他操作（如计算、数据传递）无需每次执行
都重新查找该分配的位置，直接用固定的逻辑地址引用即可，避免了频繁更新图结构的开销。

2. 关键优势：屏蔽物理内存变化

即使底层硬件（如 CUDA GPU）因内存调度（比如其他任务占用、内存回收后重新分配）导致物理内存地址变动，也不影响图的执行。

（1）原理是 “逻辑地址” 与 “物理地址” 解耦：图内部用逻辑地址关联分配，而硬件驱动（如 CUDA Runtime）负责维护
“逻辑地址→物理地址” 的映射。当物理地址变了，驱动更新映射即可，图本身无需修改，保证执行连续性。

3. 内存优化：生命周期不重叠的分配可 “复用物理内存”

在同一个图中，如果两个 “图分配” 的生命周期完全不重叠（比如 A 分配在图的第 1 阶段使用，用完后释放；B 分配在图的第 2 阶段使用，
两者没有同时存在的阶段），它们可以共用同一块底层物理内存。

（1）目的是 “内存复用”：避免为不重叠的任务重复分配物理内存，减少内存占用，尤其在 GPU 这类显存资源紧张的场景中，
能提升内存利用效率。
```

CUDA 可能会在多个图的内存分配中重用相同的物理内存，根据 GPU 有序的生命周期语义对虚拟地址映射进行别名化处理。例如，当不同的图被启动到同一个流中时，
CUDA 可能会对相同的物理内存进行虚拟别名化，以满足具有单图生命周期的分配需求。

## 2. API 基础知识

图内存节点是表示内存分配或释放操作的图节点。。简而言之，分配内存的节点称为**分配节点**。同样，释放内存的节点称为**释放节点**。由分配节点创建的分配称为**图分配**。
CUDA在节点创建时为图分配分配虚拟地址。虽然这些虚拟地址在分配节点的生命周期内是固定的，但分配的内容在释放操作后不会保持不变，并且可能会被指向不同分配的访问所覆盖。

图形分配被视为在图形每次运行时重新创建。图形分配的生命周期与节点的生命周期不同，它始于GPU执行到达分配图形节点时，并在发生以下情况之一时结束：

+ GPU执行到达释放图节点

+ GPU执行到达释放```cudaFreeAsync()```流调用

+ 在调用```cudaFree()```进行释放后立即

### 2.1 图节点 API

可以使用节点创建API ```cudaGraphAddNode``` 显式创建图形内存节点。添加 ```cudaGraphNodeTypeMemAlloc``` 节点时分配的地址会在传入的 ```cudaGraphNodeParams``` 结构的
```alloc::dptr``` 字段中返回给用户。在分配图形内部使用图形分配的所有操作都必须排在分配节点之后。同样，任何释放节点都必须排在图形内该分配的所有使用之后。释放节点是使用
```cudaGraphAddNode``` 创建的，节点类型为 ```cudaGraphNodeTypeMemFree```。

### 2.2 流捕获

可以通过捕获相应的流有序分配和释放调用```cudaMallocAsync和cudaFreeAsync```来创建图形内存节点。在这种情况下，由捕获的分配API返回的虚拟地址可被图形内部的其他操作使用。
由于流有序依赖关系会被捕获到图形中，流有序分配API的排序要求确保图形内存节点会相对于捕获的流操作进行适当排序（对于正确编写的流代码而言）。


### 2.3 在分配图外部访问和释放图内存

图分配无需由分配图释放。当一个图不释放某个分配时，该分配会在图执行结束后继续存在，并且可以被后续的CUDA操作访问。
只要通过CUDA事件和其他流排序机制确保访问操作在分配之后执行，这些分配就可以在另一个图中访问，或者直接通过流操作访问。
分配随后可通过常规调用cudaFree、cudaFreeAsync，或者通过启动带有相应释放节点的另一个图，又或者通过后续启动分配图
（如果该图是使用graph-memory-nodes-cudagraphinstantiateflagautofreeonlaunch标志实例化的）来释放。
在内存被释放后访问内存是非法的——必须通过图依赖关系、CUDA事件和其他流排序机制，确保释放操作在所有访问该内存的操作之后执行。

### 2.4 ```cudaGraphInstantiateFlagAutoFreeOnLaunch```

在正常情况下，如果图存在未释放的内存分配，CUDA会阻止其重新启动，因为在同一地址进行多次分配会导致内存泄漏。

