## 1. 简介

图内存节点允许图创建并拥有内存分配。图内存节点具有GPU有序的生命周期语义，这规定了内存何时可以在设备上被访问。这些GPU有序的生命周期语义支持驱动程序管理的内存重用，
并与流有序分配API ```cudaMallocAsync```和```cudaFreeAsync```的语义相匹配，在创建图时可能会捕获这些API。

图分配在图的整个生命周期（包括重复实例化和启动）中具有固定地址。这使得图中的其他操作可以直接引用该内存，无需更新图，即使CUDA更改了支持的物理内存也是如此。
在一个图中，图顺序生命周期不重叠的分配可以使用相同的底层物理内存。

```
1. 核心特性：图分配的 “地址固定性”

“图分配”（可理解为计算图中为数据 / 张量预留的内存空间）在整个图生命周期（包括图被多次创建实例、启动执行的全过程）中，
其 “逻辑地址” 是固定的。

（1）这里的 “固定” 不是指物理内存地址不变，而是图内部的 “引用标识” 不变 —— 图中其他操作（如计算、数据传递）无需每次执行
都重新查找该分配的位置，直接用固定的逻辑地址引用即可，避免了频繁更新图结构的开销。

2. 关键优势：屏蔽物理内存变化

即使底层硬件（如 CUDA GPU）因内存调度（比如其他任务占用、内存回收后重新分配）导致物理内存地址变动，也不影响图的执行。

（1）原理是 “逻辑地址” 与 “物理地址” 解耦：图内部用逻辑地址关联分配，而硬件驱动（如 CUDA Runtime）负责维护
“逻辑地址→物理地址” 的映射。当物理地址变了，驱动更新映射即可，图本身无需修改，保证执行连续性。

3. 内存优化：生命周期不重叠的分配可 “复用物理内存”

在同一个图中，如果两个 “图分配” 的生命周期完全不重叠（比如 A 分配在图的第 1 阶段使用，用完后释放；B 分配在图的第 2 阶段使用，
两者没有同时存在的阶段），它们可以共用同一块底层物理内存。

（1）目的是 “内存复用”：避免为不重叠的任务重复分配物理内存，减少内存占用，尤其在 GPU 这类显存资源紧张的场景中，
能提升内存利用效率。
```

CUDA 可能会在多个图的内存分配中重用相同的物理内存，根据 GPU 有序的生命周期语义对虚拟地址映射进行别名化处理。例如，当不同的图被启动到同一个流中时，
CUDA 可能会对相同的物理内存进行虚拟别名化，以满足具有单图生命周期的分配需求。

## 2. API 基础知识

