{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import time"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# CUDA 内核函数：矩阵乘法计算\n",
    "kernel_code = \"\"\"\n",
    "__global__ void matmul_optimized(float *A, float *B, float *C, int N) {\n",
    "    int row = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "    int col = threadIdx.y + blockIdx.y * blockDim.y;\n",
    "\n",
    "    if (row < N && col < N) {\n",
    "        float value = 0.0f;\n",
    "        for (int k = 0; k < N; k++) {\n",
    "            value += A[row * N + k] * B[k * N + col];\n",
    "        }\n",
    "        C[row * N + col] = value;\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ],
   "id": "c5519f1fb9e39180"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 创建 CUDA 模块\n",
    "mod = SourceModule(kernel_code)\n",
    "matmul_optimized = mod.get_function(\"matmul_optimized\")"
   ],
   "id": "99542765dc36c248"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 主机数据\n",
    "N = 1024\n",
    "A = np.random.rand(N, N).astype(np.float32)\n",
    "B = np.random.rand(N, N).astype(np.float32)\n",
    "C = np.zeros((N, N), dtype=np.float32)"
   ],
   "id": "73b58149bc48976c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 设备数据\n",
    "A_gpu = cuda.to_device(A)\n",
    "B_gpu = cuda.to_device(B)\n",
    "C_gpu = cuda.to_device(C)"
   ],
   "id": "409312db2c186ca2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 定义线程快大小和网格大小\n",
    "block_size = (32, 32, 1)   # 每个线程快包含 32 * 32 个线程\n",
    "grid_size = (N // block_size[0], N // block_size[1], 1)"
   ],
   "id": "4dc97c35eefd3738"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "start_time = time.time()    # 计算开始时间",
   "id": "2f829c6b4e1551ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 执行 CUDA 内核函数\n",
    "matmul_optimized(A_gpu, B_gpu, C_gpu, np.int32(N), block=block_size, grid=grid_size)"
   ],
   "id": "23636ec9a86afb6f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "C_gpu.get(C)",
   "id": "7b481d959632bbb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "end_time = time.time()",
   "id": "5a68333158153111"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 输出部分计算结果\n",
    "print(\"Matrix multiplication took {:.4f} seconds.\".format(end_time-start_time))\n",
    "print(\"First 5 rows and columns of the result:\")\n",
    "print(C[:5, :5])"
   ],
   "id": "5a244bcd6e3e9892"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 计算 性能指标\n",
    "# 浮点预算量\n",
    "flop_count = 2 * N ** 3"
   ],
   "id": "8dd1ffe5cee82879"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 计算吞吐量（单位：GFLOP/S）\n",
    "execution_time = end_time - start_time\n",
    "gflops = flop_count / execution_time / 1e9\n",
    "print(f\"浮点运算性能：{gflops:.4f} GFLOP/s\")"
   ],
   "id": "deac6f43284d8010"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 计算内存带块（单位：GB/s)\n",
    "# 读/写 A、B、C 矩阵，每个元素的读/写到需要消耗 4 字节的存储量\n",
    "memory_bandwidth = 2 * N * N * N * 4 / execution_time / 1e9\n",
    "print(f\"内存带宽： {memory_bandwidth:.4f} GB/s\")"
   ],
   "id": "928cf19015eb22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "识别性能瓶颈：\n",
    "\n",
    "+ 内存访问瓶颈：特别是全局内存访问；\n",
    "\n",
    "+ 计算瓶颈\n",
    "\n",
    "    程序的计算任务没有有效被分配给GPU的计算资源，则可能会导致计算单元的空闲\n",
    "\n",
    "+ 线程调度瓶颈\n",
    "\n",
    "    如果线程调度设置得不合理，则可能会导致部分线程处于等待状态。 使用 CUDA 流和事件管理可以优化线程的执行顺序，避免线程间的竞争和阻塞\n",
    "\n",
    "+ 同步瓶颈\n",
    "\n"
   ],
   "id": "396086f2c22ca15e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "计算性能与效率指标\n",
    "\n",
    "+ 浮点运算性能\n",
    "\n",
    "    浮点运算性能是指每秒完成的浮点运算次数，通常以每秒浮点运算数(FLOP/s)表示；\n",
    "\n",
    "+ 内存带宽\n",
    "\n",
    "    内存带宽是指GPU与内存之间的数据传输速率；\n",
    "\n",
    "+ 吞吐量\n",
    "\n",
    "    指的是单位时间内系统能够处理的计算任务量。吞吐量越高，GPU在执行任务时的效率越高。它与GPU的核心数、时钟频率、内存带宽等因素密切相关\n",
    "\n",
    "+ GPU 利用率\n",
    "\n",
    "    GPU利用率是衡量GPU计算资源使用情况的重要指标；"
   ],
   "id": "cdf1edbab8bfd575"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "如何计算 GPU 效率\n",
    "\n",
    "$GPU_E = \\frac{实际完成工作量}{GPU理论完成最大工作量}$"
   ],
   "id": "dce0ce5ca7293796"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
