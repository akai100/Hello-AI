在现代计算系统中，高效利用内存与最大限度发挥执行计算的功能单元的作用同样重要。异构系统拥有多个内存空间，而GPU除了缓存外，还包含多种类型的可编程片上内存。以下各节将更详细地介绍这些内存空间。

# 1. 异构系统中的DRAM存储器

GPU和CPU都有直接连接的DRAM芯片。在拥有多个GPU的系统中，每个GPU都有自己的内存。从教体代码的角度来看，**连接到GPU的DRAM被称为全局内存**，因为它可被GPU中的所有SM访问。这一术语并不意味着它一定能在系统内的所有位置被访问。
**连接到CPU的DRAM被称为系统内存或主机内存**。

与CPU类似，GPU也使用虚拟内存寻址。在所有当前支持的系统上，CPU和GPU使用单一的统一虚拟内存空间。这意味着系统中每个GPU的虚拟内存地址范围都是唯一的，且与CPU以及系统中其他所有GPU的地址范围截然不同。对于给定的虚拟内存地址，
可以确定该地址是位于GPU内存还是系统内存中；而在配备多个GPU的系统上，还能确定该地址位于哪个GPU的内存中。

有一些CUDA API可用于分配GPU内存、CPU内存，以及在CPU和GPU上的分配内存之间、同一GPU内或多GPU系统中的多个GPU之间进行数据复制。必要时，可以显式控制数据的位置。下文将讨论的统一内存允许由CUDA运行时或系统硬件自动处理内存的放置。

## 1.1 GPU 中的片上存储器

除了全局内存外，每个GPU都有一些片上内存。**每个SM都有自己的寄存器文件和共享内存**。这些内存是SM的一部分，可被SM内执行的线程极快地访问，但无法被其他SM中运行的线程访问。

寄存器文件存储**线程局部变量**，这些变量通常由编译器分配。共享内存可由线程块或集群内的所有线程访问。共享内存可用于在线程块或集群的线程之间交换数据。

SM中的寄存器文件和统一数据缓存具有有限的大小。SM的寄存器文件、统一数据缓存的大小，以及如何配置统一数据缓存以实现L1和共享内存的平衡，可在每个计算能力的内存信息中找到。
寄存器文件、共享内存空间和L1缓存由线程块中的所有线程共享。

要将线程块调度到SM上，每个线程所需的寄存器总数乘以线程块中的线程数必须小于或等于SM中的可用寄存器数。如果一个线程块所需的寄存器数量超过了寄存器文件的大小，那么该内核无法启动，必须减少线程块中的线程数，以使该线程块能够启动。

共享内存分配在线程块级别进行。也就是说，与按线程分配的寄存器不同，共享内存的分配对整个线程块是通用的。

### 1.1.1 缓存

除了可编程存储器外，GPU还拥有L1和L2缓存。每个SM都有一个L1缓存，它是统一数据缓存的一部分。更大的L2缓存由GPU内的所有SM共享。这一点可以在图2的GPU框图中看到。每个SM还有一个单独的常量缓存，用于缓存全局内存中被声明为在核函数生命周期内保持常量的值。
编译器也可能将核函数参数放入常量内存中。通过允许将核函数参数缓存在SM中，且与L1数据缓存分开，这有助于提高核函数的性能。

## 1.2 统一内存

当应用程序在GPU或CPU上显式分配内存时，该内存只能被运行在相应设备上的代码访问。也就是说，CPU内存只能被CPU代码访问，而GPU内存只能被运行在GPU上的内核访问[2]。CPU和GPU之间的内存复制CUDA API用于在适当的时候将数据显式复制到正确的内存中。

CUDA的一项名为统一内存的功能允许应用程序进行可从CPU或GPU访问的内存分配。CUDA运行时或底层硬件会在需要时实现访问或将数据迁移到正确的位置。即使使用统一内存，也要通过最大限度地减少内存迁移，并尽可能从直接连接到数据所在内存的处理器访问数据，才能获得最佳性能。


