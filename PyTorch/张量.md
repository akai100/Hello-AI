# 1. 张量介绍

张量是 Pytorch 的核心数据结构，类比 NumPy 数组但支持 GPU 加速、自动微分，是所有神经网络的底层数据载体。


# 2. 张量核心操作

## 2.1 张量创建

1. ```torch.tensor()```
   
```python3
torch.tensor(1, dtype=torch.int)               # 使用标量创建0维张量

torch.tensor([1, 2, 3], dtype=torch.int)       # 使用列表创建1维张量

torch.tensor([[1], [2], [3]], dtype=torch.int) # 使用嵌套列表创建2维张量

torch.tensor((1), dtype=torch.int)             # 使用元组创建张量

torch.tensor((1, 2, 3), (4, 5, 6))            # 使用嵌套元组创建张量

torch.tensor(np.array([1, 2, 3]), dtype=torch.int)   # 使用 Numpy 数组创建张量
```

2. ```torch.randn()```

3. ```torch.zeros()```

4. ```torch.ones()```

5. ```torch.arange()```

6. ```torch.from_numpy()```

## 2.2 设备与数据类型转换

1. ```to(device)```

```python3
```

2. ```to(dtype)```

3. ```cpu()```

4. ```cuda()```

5. ```float()```

6. ```long()```


## 2.3 维度操作

1. ```reshape()```

```python3
t = torch.randn((100, 3))
t.reshape((3, 100)) # 保持维度不变
t.reshape((3, 10, 10)) # 由2维拓展到3维
```

2. ```view()```

改变张量形状，但本质上不改变张量底层数据存储，仅修改张量的“视图（View）”。

```python3
x = torch.randn(4, 6)

y1 = x.view(2, 8)
y2 = x.view(2, 3, 4)

# 用 -1 自动推导维度
y3 = x.view(-1, 8)
y4 = x.view(2, -1, 4)

# 非连续张量不能直接 view()
x = torch.randn(4, 6)
x_transpose = x.transpose(0, 1)  # 转置后，内存非连续（contiguous=False）
# x_transpose.view(24)  # 报错：RuntimeError: view size is not compatible with input tensor's size and stride

# 解决方案：先 contiguous() 再 view()
x_contig = x_transpose.contiguous()
x_flat = x_contig.view(24)  # 正常运行
```

5. ```permute()```

维度重排操作，重新排列张量的维度顺序。与```view()```不同的是它会改变张量的内存布局。



7. ```squeeze()```

删除张量中所有大小为1的维度，本质上是修改张量的视图，不改变底层数据存储，也不改变内存连续性。

```python3
x = torch.randn(32, 1, 224, 24)

x_sq = x.squeeze()

# 删除指定单维度
x = torch.randn(8, 1, 16, 16, 1)
x_sq_dim1 = x.squeeze(dim=1)

x_sq_multi = x.squeeze(di=[1, 4])
```

9. ```unsqueeze()```

维度扩展操作，核心作用是在指定位置插入一个大小为1的维度。本质上是修改张量的视图，不改变底层数据存储，不复制数据，也不影响内存连续性。


```python3
x = torch.randn(64, 64, 64)

x_4d = x.unsqueeze(dim=1)

x_4d = x.unsqueeze(dim=-1) # 在最后一排插入
```


11. ```expand()```

维度扩展操作，核心扩展是将张量中大小为1的维度扩展为指定大小。其本质是创建数据的“广播视图”，默认不复制数据，仅通过修改张量的形状和步长实现逻辑
扩展，但会改变内存布局。

```python3
x = torch.randn(32, 1, 64, 64)
x_exp = x.expand(32, 8, 64, 64)
```


13. ```repeat()``

维度复制扩展操作，核心作用是将张量按指定次数复制扩展维度。其本质是物理复制数据

```python3
x_single = torch.randn(32, 1, 224, 224)
x_multi = x_single.repeat(1, 3, 1, 1)   # C 维度复制3次
```

15. ```split()```

张量分割操作，核心作用是将张量按指定维度和方式分割为多个子张量，其本质上是创建原始张量的视图，默认不复制数据，

17. ```chunk()```

18. ```cat()```

19. ```stack()```

## 2.4 索引与切片

1. 基础索引

2. 高级索引

3. ```masked_fill()```

4. ```take()```

5. ```gather()```


## 2.5 数学运算

1. 算数运算

2. 矩阵乘法

3. 批量矩阵乘

4. 聚合运算

5. 广播机制

# 3. 属性


   
