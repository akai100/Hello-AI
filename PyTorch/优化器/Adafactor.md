# Adafactor.md

Adafactor 是一种内存高效的自适应优化器，由 Noam Shazeer 和 Mitchell Stern 于 2018 年在论文《Adafactor: Adaptive Learning Rates with Sublinear Memory Cost》中提出。
它的核心优势是大幅降低内存占用，同时保持与 Adam 相当的收敛性能，特别适合大规模模型训练（如 BERT、GPT 等）
