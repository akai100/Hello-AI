在AMD Instinct MI200 GPU上，FP16和BF16的V_DOT2及MFMA矩阵指令会将输入和输出的非正规值刷新为零。

FP32和FP64的MFMA矩阵指令不会将输入和输出的非正规值刷新为零。

受影响的指令仅被rocBLAS（GEMM）和MIOpen（卷积）内核使用；所有其他PyTorch操作不会出现此情况。所有其他受支持的AMD GPU也不会出现此情况。

rocBLAS和MIOpen为受影响的FP16运算提供了替代实现。未提供BF16运算的替代实现；BF16数字的动态范围比FP16数字更大，且不太可能出现非正规值。
对于FP16的替代实现，FP16输入值会被转换为中间的BF16值，在FP32累加运算后再转换回FP16输出。通过这种方式，输入和输出类型保持不变。

使用FP16精度进行训练时，一些模型可能会因FP16非规格化数被置零而无法收敛。非规格化数值在训练的反向传播过程中进行梯度计算时更常出现。
'PyTorch在反向传播过程中默认会使用rocBLAS和MIOpen的替代实现。可以通过环境变量```ROCBLAS_INTERNAL_FP16_ALT_IMPL和MIOPEN_DEBUG_CONVOLUTION_ATTRIB_FP16_ALT_IMPL```来覆盖默认行为。这些环境变量的作用如下：
